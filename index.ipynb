{
  "cells": [
    {
      "cell_type": "raw",
      "metadata": {},
      "source": [
        "---\n",
        "title: Fine-Tuning Transformer Models for Classification of Digital Behavioural Data\n",
        "author:\n",
        "  - name:\n",
        "      given: Indira\n",
        "      family: Sen\n",
        "    affiliations:\n",
        "      - name: RWTH Aachen University\n",
        "bibliography: references.bib\n",
        "csl: apa.csl\n",
        "format:\n",
        "  html: default\n",
        "  ipynb: default\n",
        "---"
      ],
      "id": "1ea87726"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Learning Objectives\n",
        "\n",
        "By the end of this tutorial, you will be able to fine-tune transformer models like BERT for binary and multiclass document classification. We show two options for using transformer models in Python\n",
        "\n",
        "- Simple Transformers\n",
        "- HuggingFace\n",
        "\n",
        "As an example, we will fine-tune a specific transformer model (DistilBERT) for automatic sexism detection. \n",
        "\n",
        "## Target audience\n",
        "\n",
        "This tutorial is aimed at social scientists with some knowledge in Python and supervised machine learning.\n",
        "\n",
        "## Setting up the computational environment\n",
        "\n",
        "The following Python packages are required\n",
        "\n",
        "```python\n",
        "!pip install pandas numpy torch sklearn\n",
        "!pip install simpletransformers\n",
        "!pip install transformers[torch]\n",
        "```\n",
        "\n",
        "This package is optional\n",
        "\n",
        "```python\n",
        "!pip install accelerate -U\n",
        "```\n",
        "\n",
        "## Duration\n",
        "\n",
        "It depends on the hardware. This notebook can be used with or without GPU compute, but it's much faster if you do have a GPU.\n",
        "\n",
        "## Social Science Usecase(s)\n",
        "\n",
        "This method has been used in @samory2021call for automatic sexism detection.\n",
        "\n",
        "## Import necessary Python libraries and modules\n",
        "\n",
        "We will import necessary Python libraries and modules.\n"
      ],
      "id": "98e3e01d"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "# For deep learning\n",
        "import torch"
      ],
      "id": "100b4faf",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We then check if have a GPU available. This is important because some parts of the code have to be modified later on based on this.\n"
      ],
      "id": "8efb87ef"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "gpu_avail = torch.cuda.is_available()\n",
        "gpu_avail"
      ],
      "id": "f5963214",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Get the data\n",
        "\n",
        "We first download the datasets we need for finetuning our models. This is a **supervised** classification task, therefore, we will need labeled data. We download the the 'Call me sexist but' (CMSB) dataset which you can find here: [https://search.gesis.org/research_data/SDN-10.7802-2251](https://search.gesis.org/research_data/SDN-10.7802-2251) This dataset is from our paper on detecting sexism in a theory-driven manner [@samory2021call].\n",
        "\n",
        "Here, we can download the full data ('sexism\\_data.csv') and put it in folder called 'sexism_data' in the same location as our jupyter notebook. Here, we will use just a subset of the data for demonstration.\n"
      ],
      "id": "8cbe4c04"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "## sexism_data = pd.read_csv('sexism_data/sexism_data.csv')\n",
        "\n",
        "sexism_data = pd.read_csv('sexism_data/sexism_sample.csv')\n",
        "\n",
        "sexism_data.head()"
      ],
      "id": "16ae9d9e",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "sexism_data = sexism_data.dropna(subset = 'sexist')"
      ],
      "id": "2615e229",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Finetuning a classifier: the general procedure\n",
        "\n",
        "### With `simpletransformers`\n",
        "\n",
        "We first use the [`simpletransformers`](https://simpletransformers.ai/) package which is more beginner-friendly. The basic steps for finetuning a classifier using simpletrasnformers are:\n",
        "\n",
        "- Initialize a model based on a specific architechture (BERT, DistilBERT, etc)\n",
        "- Train the model with train_model()\n",
        "- Evaluate the model with eval_model()\n",
        "- Make predictions on (unlabelled) data with predict()\n"
      ],
      "id": "8ae10e64"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "from simpletransformers.classification import ClassificationModel, ClassificationArgs\n",
        "import logging"
      ],
      "id": "fa5e1899",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "#| eval: false\n",
        "logging.basicConfig(level=logging.INFO)\n",
        "transformers_logger = logging.getLogger(\"transformers\")\n",
        "transformers_logger.setLevel(logging.WARNING)"
      ],
      "id": "6b082975",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We need to preprocess the data first before we start the finetuning process. In this step, we split the dataset into **train** and **test** sets to have a fully held-out test set that can be used to evaluate our classifier.\n",
        "\n",
        "We can also create a **validation** that is used during the fine tuning process for hyperparameter tuning, but that is not mandatory.\n"
      ],
      "id": "ff26cc7a"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "train_df, test_df = train_test_split(sexism_data, stratify=sexism_data['sexist'], test_size=0.2)"
      ],
      "id": "116ecd1d",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We now convert the dataframes into a format that can be read by simpletransformers. This is a dataframe with the columns 'text' and 'labels'. The 'labels' column should be numerical, so we use **one-hot encoding** to transform our boolean sexist labels to numerical ones.\n"
      ],
      "id": "3ec0a07f"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "from sklearn.preprocessing import LabelEncoder\n",
        "le = LabelEncoder()\n",
        "le.fit(train_df['sexist'])\n",
        "train_df['labels'] = le.transform(train_df['sexist'])\n",
        "test_df['labels'] = le.transform(test_df['sexist'])"
      ],
      "id": "b8169836",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# to see which number was mapped to which class:\n",
        "list(le.inverse_transform([0,1]))"
      ],
      "id": "d8de1e5e",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "So, 0 is non-sexist and 1 is sexist. We now have the appropriate data structure.\n",
        "\n",
        "The next step is setting the training parameters and loading the classification model, in this case, DistilBERT [@sanh2019distilbert], a lightweight model that can be trained relatively quickly compared to other transformer variants like BERT and RoBERTa.\n",
        "\n",
        "For training parameters, we have many to choose from such as the learning rate, whether we want to stop early or not, where we should save the model, and more. You can find all of them [here](https://simpletransformers.ai/docs/usage/#configuring-a-simple-transformers-model).\n",
        "\n",
        "As a minimal setup, we will just set the number of **epochs**, i.e., the number of passes the model does over the full training set. For recent transformer models, epochs are usually set to 2 or 3, after which overfitting may happen.\n",
        "\n",
        "**use_cuda** is a parameter that signals whether the GPU should be used or not. It will be set based on our check earlier.\n"
      ],
      "id": "09302ab2"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Optional model configuration\n",
        "model_args = ClassificationArgs(num_train_epochs=3, overwrite_output_dir=True)\n",
        "\n",
        "# Create a ClassificationModel\n",
        "model = ClassificationModel(\n",
        "    \"distilbert\", \"distilbert-base-uncased\", args=model_args, use_cuda=gpu_avail,\n",
        ")\n",
        "\n",
        "# we set some additional parameters when using a GPU\n",
        "if gpu_avail:\n",
        "    model_args.use_multiprocessing=False\n",
        "    model_args.use_multiprocessing_for_evaluation=False"
      ],
      "id": "60e369a2",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We are now finally ready to begin training! This might take a while, especially when we're not using a GPU.\n"
      ],
      "id": "cae2bcc3"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Train the model\n",
        "model.train_model(train_df)"
      ],
      "id": "1268c2a4",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "After training our model, we can use it to make predictions for unlabeled datapoints to classify whether they are sexist or not.\n"
      ],
      "id": "cb2bbbea"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "sexist_tweet = \"A woman will never be truly fulfilled in life if she doesnâ€™t have a committed long-term relationship with a man\"\n",
        "predictions, raw_outputs = model.predict([sexist_tweet])\n",
        "le.inverse_transform(predictions)"
      ],
      "id": "494bf8c2",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We can also use the held-out test set to quantitatively evaluate our model.\n"
      ],
      "id": "c57b3350"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "#| eval: false\n",
        "# Evaluate the model\n",
        "result, model_outputs, wrong_predictions = model.eval_model(test_df)\n",
        "result"
      ],
      "id": "b6364e74",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "#| eval: false\n",
        "# you can also use sklearn's neat classification report to get more metrics\n",
        "from sklearn.metrics import classification_report\n",
        "\n",
        "preds, _ = model.predict(list(test_df['text'].values))\n",
        "# preds = le.inverse_transform(preds)\n",
        "\n",
        "print(classification_report(test_df['labels'], preds))"
      ],
      "id": "f7b4ed2d",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### With HuggingFace `transformers`\n",
        "\n",
        "We now repeat the same process with the HuggingFace [`transformers` Python library](https://huggingface.co/transformers/installation.html). Additionally, we also use the [accelerate library](https://huggingface.co/docs/accelerate/index), which helps make our code more efficient. \n",
        "We will again use DistilBERT.\n"
      ],
      "id": "693c6739"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "from transformers import DistilBertTokenizerFast, DistilBertForSequenceClassification\n",
        "from transformers import Trainer, TrainingArguments"
      ],
      "id": "393857c1",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We will set some of the configurations, including whether to use a GPU or not.\n"
      ],
      "id": "17868ea8"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "#| eval: false\n",
        "model_name = 'distilbert-base-uncased'\n",
        "if gpu_avail:\n",
        "    device_name = 'cuda'\n",
        "else:\n",
        "    device_name = 'cpu'\n",
        "\n",
        "# This is the maximum number of tokens in any document; the rest will be truncated.\n",
        "max_length = 512\n",
        "\n",
        "# This is the name of the directory where we'll save our model. You can name it whatever you want.\n",
        "cached_model_directory_name = 'output_hf'"
      ],
      "id": "479772bd",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We will reuse the train-test splits we created for simpletransformers, but change the data structure slightly.\n"
      ],
      "id": "fd586e6d"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "#| eval: false\n",
        "train_texts = train_df['text'].values\n",
        "train_labels = train_df['labels'].values\n",
        "\n",
        "test_texts = test_df['text'].values\n",
        "test_labels = test_df['labels'].values"
      ],
      "id": "a853533b",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Compared to simpletransformers, we get a closer look at what happens 'under the hood' with huggingface. We will see the transformation of the text better --- each tweet will be truncated if they're more than 512 tokens or padded if they're fewer than 512 tokens.\n",
        "\n",
        "The tokens will be separated into \"word pieces\" using the transformers tokenizers ('DistilBertTokenizerFast' in this case to match the DistiBERT model). And some special tokens will also be added such as **CLS** (start token of every tweet) and **SEP** (separator between each sentence {not tweet}):\n"
      ],
      "id": "e038ae4e"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "#| eval: false\n",
        "tokenizer = DistilBertTokenizerFast.from_pretrained(model_name)"
      ],
      "id": "742fb83f",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We now encode our texts using the tokenizer.\n"
      ],
      "id": "359fbe5a"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "#| eval: false\n",
        "from datasets import Dataset\n",
        "\n",
        "train_df = Dataset.from_pandas(train_df)\n",
        "test_df = Dataset.from_pandas(test_df)\n",
        "\n",
        "def tokenize_function(examples):\n",
        "    return tokenizer(examples[\"text\"], padding=\"max_length\", truncation=True)\n",
        "\n",
        "\n",
        "tokenized_train_df = train_df.map(tokenize_function, batched=True)\n",
        "tokenized_test_df = test_df.map(tokenize_function, batched=True)"
      ],
      "id": "7f0afabd",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We now load the DistilBERT model and specify that it should use the GPU.\n"
      ],
      "id": "61f7de06"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "#| eval: false\n",
        "model = DistilBertForSequenceClassification.from_pretrained(model_name, num_labels=len(le.classes_)).to()"
      ],
      "id": "209ec272",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "As we did with simpletransformers, we now set the training parameters, i.e., the number of epochs.\n"
      ],
      "id": "5ea77dda"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "#| eval: false\n",
        "import accelerate"
      ],
      "id": "f06fab47",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "#| eval: false\n",
        "training_args = TrainingArguments(\n",
        "    num_train_epochs=3,              # total number of training epochs\n",
        "    output_dir='./results',          # output directory\n",
        "    report_to='none'\n",
        ")"
      ],
      "id": "5ac0d16b",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Fine-tune the DistilBERT model\n",
        "\n",
        "First, we define a custom evaluation function that returns the accuracy. You could modify this function to return precision, recall, F1, and/or other metrics.\n"
      ],
      "id": "d196f1b5"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "#| eval: false\n",
        "from sklearn.metrics import accuracy_score\n",
        "def compute_metrics(pred):\n",
        "    labels = pred.label_ids\n",
        "    preds = pred.predictions.argmax(-1)\n",
        "    acc = accuracy_score(labels, preds)\n",
        "    return {\n",
        "        'accuracy': acc,\n",
        "  }"
      ],
      "id": "9b60a863",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Then we create a HuggingFace `Trainer` object using the `TrainingArguments` object that we created above. We also send our `compute_metrics` function to the `Trainer` object, along with our test and train datasets.\n"
      ],
      "id": "5755e501"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "#| eval: false\n",
        "trainer = Trainer(\n",
        "    model=model,                         # the instantiated ðŸ¤— Transformers model to be trained\n",
        "    args=training_args,                  # training arguments, defined above\n",
        "    train_dataset=tokenized_train_df,         # training dataset\n",
        "    compute_metrics=compute_metrics      # our custom evaluation function\n",
        ")"
      ],
      "id": "166db8a6",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Time to finally fine-tune!\n"
      ],
      "id": "f95b813f"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "#| eval: false\n",
        "trainer.train()"
      ],
      "id": "e9b0813c",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Save fine-tuned model\n",
        "\n",
        "The following cell will save the model and its configuration files to a directory in Colab. To preserve this model for future use, you should download the model to your computer.\n"
      ],
      "id": "daff6823"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "#| eval: false\n",
        "trainer.save_model(cached_model_directory_name)"
      ],
      "id": "c75f22b0",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "(Optional) If you've already fine-tuned and saved the model, you can reload it using the following line. You don't have to run fine-tuning every time you want to evaluate.\n"
      ],
      "id": "7b26b686"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "#| eval: false\n",
        "# trainer = DistilBertForSequenceClassification.from_pretrained(cached_model_directory_name)"
      ],
      "id": "2624a7f2",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We can now evaluate the model by predicting the labels for the test set.\n"
      ],
      "id": "069ee299"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "#| eval: false\n",
        "predicted_results = trainer.predict(tokenized_test_df)"
      ],
      "id": "9b59cd88",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "#| eval: false\n",
        "predicted_labels = predicted_results.predictions.argmax(-1) # Get the highest probability prediction\n",
        "predicted_labels = predicted_labels.flatten().tolist()      # Flatten the predictions into a 1D list\n",
        "predicted_labels[0:5]"
      ],
      "id": "c899a973",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "#| eval: false\n",
        "print(classification_report(tokenized_test_df['labels'],\n",
        "                            predicted_labels))"
      ],
      "id": "5ab68488",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "You can now use this classifier on other types of data to label it for potentially sexist content.\n",
        "\n",
        "## Multi-class classification\n",
        "\n",
        "In the previous parts, we finetuned a binary classifier for differentiating sexist vs. non-sexist content. However, the CMSB dataset has fine-grained labels for sexism based on **content** and **phrasing**.\n",
        "\n",
        "So we now use a multi-class classifier using simpletransformers, with a few tweaks to our earlier code.  \n",
        "\n",
        "But first, we have to aggregate the annotations from all crowdworkers to obtain the content and phrasing labels. For simplicity, we will use the majority label (breaking ties randomly).\n"
      ],
      "id": "37d12e87"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "#| eval: false\n",
        "sexism_data_annotations = pd.read_csv('sexism_data/all_data_annotations.csv', sep = '\\t')\n",
        "sexism_data_annotations.head()"
      ],
      "id": "a6685056",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "#| eval: false\n",
        "tweets = sexism_data_annotations['_id'].unique()"
      ],
      "id": "a6390109",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "#| eval: false\n",
        "from collections import Counter\n",
        "\n",
        "content_labels = []\n",
        "phrasing_labels = []\n",
        "\n",
        "for tweet in tweets:\n",
        "    data_subset = sexism_data_annotations[sexism_data_annotations['_id'] == tweet]\n",
        "    content_labels.append(Counter(data_subset['content'].values).most_common()[0][0]) # get the majority label for content\n",
        "    phrasing_labels.append(Counter(data_subset['phrasing']).most_common()[0][0]) # get the majority label for phrasing"
      ],
      "id": "74f62d96",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "#| eval: false\n",
        "finegrained_sexism_data = pd.DataFrame([tweets, content_labels, phrasing_labels]).T\n",
        "finegrained_sexism_data.columns = ['_id', 'content_label', 'phrasing_label']\n",
        "finegrained_sexism_data"
      ],
      "id": "0f727c3d",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "#| eval: false\n",
        "finegrained_sexism_data.groupby('content_label').size()"
      ],
      "id": "2df9549b",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "#| eval: false\n",
        "finegrained_sexism_data.groupby('phrasing_label').size()"
      ],
      "id": "07854016",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The six content and three phrasing categories are:\n",
        "\n",
        "![](img/img1.png)\n",
        "\n",
        "Let's join this data with the tweets data from 'all_data.csv'\n"
      ],
      "id": "ed715e03"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "#| eval: false\n",
        "\n",
        "finegrained_sexism_data = pd.merge(finegrained_sexism_data, sexism_data[['_id', 'text', 'sexist']])"
      ],
      "id": "62cb9408",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "#| eval: false\n",
        "finegrained_sexism_data.groupby(['content_label']).size()"
      ],
      "id": "92d42e09",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Since our dataset is somewhat imbalanced with low representation for some categories, we can restrict it to only those classes that have at least 300 instances, i.e., 1, 2, and 6.\n"
      ],
      "id": "2bc40d37"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "#| eval: false\n",
        "finegrained_sexism_data = finegrained_sexism_data[finegrained_sexism_data['content_label'].isin([1, 2, 6])]\n",
        "\n",
        "# we also change the label range for simpletransformers, making them range from 0 to 2.\n",
        "label_map = {1 : 0,\n",
        "             2 : 1,\n",
        "             6 : 2}\n",
        "finegrained_sexism_data['content_label'] = [label_map[i] for i in finegrained_sexism_data['content_label']]\n",
        "finegrained_sexism_data.groupby(['content_label']).size()"
      ],
      "id": "035bfe27",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Let's train a classifier for identifying sexist content or phrasing\n"
      ],
      "id": "bbcf7727"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "#| eval: false\n",
        "category = 'content_label'"
      ],
      "id": "79a4a0f2",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "#| eval: false\n",
        "multi_train_df, multi_test_df = train_test_split(finegrained_sexism_data,\n",
        "                                                 stratify=finegrained_sexism_data[category],\n",
        "                                                 test_size=0.2)"
      ],
      "id": "dc23f727",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "You have the add the number of labels to the model initialization.\n"
      ],
      "id": "7a2355dc"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "#| eval: false\n",
        "# Optional model configuration\n",
        "model_args = ClassificationArgs(num_train_epochs=5,\n",
        "                                output_dir='output_st',\n",
        "                                overwrite_output_dir=True)\n",
        "\n",
        "# Create a ClassificationModel\n",
        "model = ClassificationModel(\n",
        "    \"distilbert\", \"distilbert-base-uncased\", num_labels=len(finegrained_sexism_data[category].unique()),\n",
        "    use_cuda=gpu_avail,\n",
        "    args=model_args\n",
        ")\n",
        "\n",
        "\n",
        "# we set some additional parameters when using a GPU\n",
        "if gpu_avail:\n",
        "    model_args.use_multiprocessing=False\n",
        "    model_args.use_multiprocessing_for_evaluation=False"
      ],
      "id": "48b3cacd",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "#| eval: false\n",
        "# multi_train_df['content_label'] = [i-1 for i in multi_train_df['content_label']]\n",
        "# multi_test_df['content_label'] = [i-1 for i in multi_test_df['content_label']]"
      ],
      "id": "a6dc1e72",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "#| eval: false\n",
        "multi_train_df = multi_train_df[['text', category]]\n",
        "multi_test_df = multi_test_df[['text', category]]"
      ],
      "id": "78dc71ba",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "#| eval: false\n",
        "# Train the model.\n",
        "model.train_model(multi_train_df)"
      ],
      "id": "62983fc0",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "#| eval: false\n",
        "predictions, raw_outputs = model.predict([sexist_tweet])\n",
        "predictions"
      ],
      "id": "10fcd9a7",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "#| eval: false\n",
        "preds, _ = model.predict(list(multi_test_df['text'].values))"
      ],
      "id": "d4240354",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "#| eval: false\n",
        "print(classification_report(multi_test_df[category], preds))"
      ],
      "id": "fa6ee6f3",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We can see that the model performs worse than binary sexism classification, but still better than a random chance model which would have add an accuracy of 0.3 as we have three classes.\n",
        "\n",
        "## Conclusion\n",
        "\n",
        "That's a wrap on fine-tuning your own transformer models for text classification. You can replace the sexism dataset with any other labeled dataset of your choice for a particular task to train a classifier for that task. More further reading and examples, see:\n",
        "\n",
        "- [https://www.aiforhumanists.com/tutorials/](https://www.aiforhumanists.com/tutorials/)\n",
        "- [https://huggingface.co/docs/transformers/en/training](https://huggingface.co/docs/transformers/en/training)"
      ],
      "id": "e409bff3"
    }
  ],
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "language": "python",
      "display_name": "Python 3 (ipykernel)"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}